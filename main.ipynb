{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OXeEdPHmSjA",
        "outputId": "60ae5124-67e4-4cff-c045-b4da1ed35841"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "GITHUB_USERNAME = \"MUKAMAFrancois\"\n",
        "REPO_NAME       = \"TTS_tecGrw\"\n",
        "GITHUB_TOKEN    = userdata.get('GITHUB_TOKEN')\n",
        "project_dir     = f\"/content/{REPO_NAME}\"\n",
        "\n",
        "if os.path.exists(project_dir):\n",
        "    print(\"ðŸ”„ Updating project repo...\")\n",
        "    %cd {project_dir}\n",
        "    !git pull\n",
        "else:\n",
        "    print(\"ðŸ“¥ Cloning project repo...\")\n",
        "    repo_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
        "    !git clone {repo_url} {project_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgNP86OYmSfs"
      },
      "outputs": [],
      "source": [
        "os.chdir(f\"/content/{REPO_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMhQ-X-D5RAR"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q \"transformers>=4.56,<5\" \"tokenizers>=0.22,<0.24\" accelerate tqdm torchaudio datasets pyyaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW3lam6R6RvQ"
      },
      "source": [
        "### speaker analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCoTXtcW5Q84"
      },
      "outputs": [],
      "source": [
        "from src.loader import load_config, get_hf_token\n",
        "from src.analytics import run_speaker_analysis\n",
        "\n",
        "config = load_config()\n",
        "\n",
        "# Auto-fetches from Colab secrets (key: HF_TOKEN)\n",
        "token = get_hf_token()\n",
        "\n",
        "stats, best_speaker = run_speaker_analysis(config, token)\n",
        "\n",
        "print(stats)\n",
        "print(\"Recommended speaker:\", best_speaker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg2n6J0L6Ox1"
      },
      "source": [
        "## splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewCVlw3b5Q6f"
      },
      "outputs": [],
      "source": [
        "from src.loader import load_all_splits, combine_splits\n",
        "\n",
        "splits = load_all_splits(config, token)\n",
        "\n",
        "print(len(splits[\"train\"]))\n",
        "print(len(splits[\"validation\"]))\n",
        "print(len(splits[\"test\"]))\n",
        "\n",
        "combined = combine_splits(splits)\n",
        "print(\"Total:\", len(combined))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Js6uN-K6JoS"
      },
      "source": [
        "### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrx0jBBV5Q4E"
      },
      "outputs": [],
      "source": [
        "from src.loader import load_config, get_hf_token\n",
        "from src.preprocess import run_preprocessing_pipeline\n",
        "\n",
        "config = load_config()\n",
        "token = get_hf_token()\n",
        "\n",
        "stats = run_preprocessing_pipeline(config, token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx2UP_T26GYD"
      },
      "source": [
        "## pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iggq9kU75Q0_"
      },
      "outputs": [],
      "source": [
        "from src.loader import load_config, ensure_dir\n",
        "from src.model import (\n",
        "    load_model_and_tokenizer,\n",
        "    synthesize_speech,\n",
        "    save_waveform\n",
        ")\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "config = load_config()\n",
        "ensure_dir(\"evaluation/synthesized_wavs\")\n",
        "\n",
        "# Load pretrained facebook/mms-tts-kin\n",
        "model, tokenizer = load_model_and_tokenizer(config)\n",
        "\n",
        "text = \"Muraho, nagufasha gute uyu munsi?\"\n",
        "waveform, sr = synthesize_speech(model, tokenizer, text)\n",
        "\n",
        "output_path = \"evaluation/synthesized_wavs/pretrained_test.wav\"\n",
        "save_waveform(waveform, sr, output_path)\n",
        "\n",
        "print(f\"Saved to: {output_path}\")\n",
        "print(f\"Sample rate: {sr}\")\n",
        "print(f\"Waveform shape: {waveform.shape}\")\n",
        "\n",
        "display(Audio(output_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye_PdrI25QyH"
      },
      "outputs": [],
      "source": [
        "# count parameters\n",
        "from src.model import count_parameters\n",
        "print(count_parameters(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50BTGGWr59ZP"
      },
      "source": [
        "## pre-trained test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GumBTPXd5hQR"
      },
      "outputs": [],
      "source": [
        "test_sentences = [\n",
        "    \"Muraho, nagufasha gute uyu munsi?\",\n",
        "    \"Niba ufite ibibazo bijyanye n'ubuzima bwawe, twagufasha.\",\n",
        "    \"Ni ngombwa ko ubonana umuganga vuba.\",\n",
        "    \"Twabanye nawe kandi tuzakomeza kukwitaho.\",\n",
        "    \"Ushobora kuduhamagara igihe cyose ukeneye ubufasha.\"\n",
        "]\n",
        "\n",
        "for i, text in enumerate(test_sentences):\n",
        "    waveform, sr = synthesize_speech(model, tokenizer, text)\n",
        "    path = f\"evaluation/synthesized_wavs/pretrained_{i}.wav\"\n",
        "    save_waveform(waveform, sr, path)\n",
        "    print(path)\n",
        "    display(Audio(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from src.loader import load_config\n",
        "from src.model import load_model_and_tokenizer, get_device\n",
        "from src.training.dataset import create_dataloader\n",
        "from src.training.trainer import Trainer\n",
        "\n",
        "def resolve_metadata_path(config, key):\n",
        "    raw_path = config.get(key)\n",
        "    if raw_path is None:\n",
        "        return None\n",
        "    if os.path.exists(raw_path):\n",
        "        return raw_path\n",
        "    processed_dir = config.get(\"PROCESSED_DIR\", \"\")\n",
        "    candidate = os.path.join(processed_dir, os.path.basename(raw_path))\n",
        "    if os.path.exists(candidate):\n",
        "        return candidate\n",
        "    return raw_path\n",
        "\n",
        "config = load_config()\n",
        "device = get_device()\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model, tokenizer = load_model_and_tokenizer(config, device)\n",
        "\n",
        "train_metadata = resolve_metadata_path(config, \"TRAIN_METADATA\")\n",
        "val_metadata = resolve_metadata_path(config, \"VAL_METADATA\")\n",
        "\n",
        "train_loader = create_dataloader(\n",
        "    train_metadata,\n",
        "    tokenizer,\n",
        "    config[\"TARGET_SAMPLE_RATE\"],\n",
        "    config[\"BATCH_SIZE\"],\n",
        "    shuffle=True,\n",
        "    num_workers=int(config.get(\"NUM_WORKERS\", 2)),\n",
        "    max_batch_duration_sec=config.get(\"MAX_BATCH_DURATION_SEC\")\n",
        ")\n",
        "\n",
        "val_loader = None\n",
        "if val_metadata is not None and os.path.exists(val_metadata):\n",
        "    val_loader = create_dataloader(\n",
        "        val_metadata,\n",
        "        tokenizer,\n",
        "        config[\"TARGET_SAMPLE_RATE\"],\n",
        "        config[\"BATCH_SIZE\"],\n",
        "        shuffle=False,\n",
        "        num_workers=int(config.get(\"NUM_WORKERS\", 2)),\n",
        "        max_batch_duration_sec=config.get(\"VAL_MAX_BATCH_DURATION_SEC\")\n",
        "    )\n",
        "    print(\"Validation loader enabled.\")\n",
        "else:\n",
        "    print(\"Validation metadata not found, validation disabled.\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    config,\n",
        "    device,\n",
        "    use_amp=bool(config.get(\"USE_AMP\", True))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stages = config.get(\"STAGES\", [\n",
        "    {\"stage\": 1, \"lr\": 1e-4, \"epochs\": 3},\n",
        "    {\"stage\": 2, \"lr\": 5e-5, \"epochs\": 2},\n",
        "    {\"stage\": 3, \"lr\": 1e-5, \"epochs\": 1},\n",
        "])\n",
        "\n",
        "for stage_cfg in stages:\n",
        "    trainer.train_stage(\n",
        "        stage=int(stage_cfg[\"stage\"]),\n",
        "        lr=float(stage_cfg[\"lr\"]),\n",
        "        epochs=int(stage_cfg[\"epochs\"])\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "from src.loader import load_config\n",
        "from src.model import (\n",
        "    get_device,\n",
        "    load_model_and_tokenizer,\n",
        "    load_checkpoint,\n",
        ")\n",
        "\n",
        "config = load_config()\n",
        "device = get_device()\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def find_latest_checkpoint(checkpoint_dir):\n",
        "    ckpt_dir = Path(checkpoint_dir)\n",
        "    if not ckpt_dir.exists():\n",
        "        raise FileNotFoundError(f\"Checkpoint directory not found: {checkpoint_dir}\")\n",
        "\n",
        "    matches = []\n",
        "    for p in ckpt_dir.iterdir():\n",
        "        if p.is_dir():\n",
        "            m = re.match(r\"checkpoint_(\\d+)$\", p.name)\n",
        "            if m:\n",
        "                matches.append((int(m.group(1)), p))\n",
        "\n",
        "    if not matches:\n",
        "        raise FileNotFoundError(f\"No checkpoint_<step> folders found in: {checkpoint_dir}\")\n",
        "\n",
        "    matches.sort(key=lambda x: x[0])\n",
        "    return matches[-1][0], str(matches[-1][1])\n",
        "\n",
        "latest_step, latest_ckpt_path = find_latest_checkpoint(config.get(\"CHECKPOINT_DIR\", \"checkpoints\"))\n",
        "print(f\"Latest checkpoint: {latest_ckpt_path} (step={latest_step})\")\n",
        "\n",
        "pretrained_model, pretrained_tokenizer = load_model_and_tokenizer(config, device)\n",
        "final_model, final_tokenizer = load_checkpoint(latest_ckpt_path, device)\n",
        "\n",
        "print(\"Models loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from src.model import synthesize_speech, save_waveform\n",
        "\n",
        "test_sentences = [\n",
        "    \"Muraho, nagufasha gute uyu munsi?\",\n",
        "    \"Niba ufite ibibazo bijyanye n'ubuzima bwawe, twagufasha.\",\n",
        "    \"Ni ngombwa ko ubonana umuganga vuba.\",\n",
        "    \"Twabanye nawe kandi tuzakomeza kukwitaho.\",\n",
        "    \"Ushobora kuduhamagara igihe cyose ukeneye ubufasha.\"\n",
        "]\n",
        "\n",
        "compare_dir = \"evaluation/compare_pretrained_vs_final\"\n",
        "os.makedirs(compare_dir, exist_ok=True)\n",
        "\n",
        "rows = []\n",
        "for i, text in enumerate(test_sentences):\n",
        "    pre_wav, pre_sr = synthesize_speech(pretrained_model, pretrained_tokenizer, text, device)\n",
        "    fin_wav, fin_sr = synthesize_speech(final_model, final_tokenizer, text, device)\n",
        "\n",
        "    pre_path = f\"{compare_dir}/sentence_{i:02d}_pretrained.wav\"\n",
        "    fin_path = f\"{compare_dir}/sentence_{i:02d}_final.wav\"\n",
        "\n",
        "    save_waveform(pre_wav, pre_sr, pre_path)\n",
        "    save_waveform(fin_wav, fin_sr, fin_path)\n",
        "\n",
        "    rows.append({\n",
        "        \"idx\": i,\n",
        "        \"text\": text,\n",
        "        \"pretrained_path\": pre_path,\n",
        "        \"final_path\": fin_path,\n",
        "        \"pretrained_duration_sec\": pre_wav.shape[-1] / pre_sr,\n",
        "        \"final_duration_sec\": fin_wav.shape[-1] / fin_sr,\n",
        "    })\n",
        "\n",
        "compare_df = pd.DataFrame(rows)\n",
        "compare_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Audio, display, Markdown\n",
        "\n",
        "for _, r in compare_df.iterrows():\n",
        "    display(Markdown(f\"### Sentence {int(r['idx'])}\\n`{r['text']}`\"))\n",
        "    print(\"Pre-trained\")\n",
        "    display(Audio(r[\"pretrained_path\"]))\n",
        "    print(\"Final fine-tuned\")\n",
        "    display(Audio(r[\"final_path\"]))\n",
        "    print(f\"Durations (s) -> pre: {r['pretrained_duration_sec']:.2f}, final: {r['final_duration_sec']:.2f}\")\n",
        "    print(\"-\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tecGrw",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
